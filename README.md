# Denoising Diffusion Probabilistic Models Papers
Papers club from the AI team in D-ID  - this time Diffusion Model(DM).

Diffusion Models were first introduced in [Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://arxiv.org/abs/1503.03585). However, it took until [Generative Modeling by Estimating Gradients of the Data Distribution](https://arxiv.org/abs/1907.05600) (Song et al., 2019, Stanford University) & , and then [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) (Ho et al., 2020, Google Brain) who independently improved the approach.

A good explnantion on what are Diffusion Models and why they are intresting can be found in [Diffusion-Models](https://youtu.be/cS6JQpEY9cs)


מועדון קריאת מאמרים שלנו - כל ההרצאות בעיברית
| Title | Paper / Resource | Year | Why is it interesting? | Asignee | Recording | Slides |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|Denoising Diffusion Probabilistic Models|[Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) | 2020 | <details><summary>read why</summary>high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics.</details> | []() | | |
|The Annotated Diffusion Model |[The Annotated Diffusion Model](https://huggingface.co/blog/annotated-diffusion) |  | <details><summary>read why</summary></details> | [self-work]() | -- |--|
| Super-Resolution |[Image Super-Resolution via Iterative Refinement](https://arxiv.org/abs/2104.07636) | 2021 | <details><summary>read why</summary>denoising diffusion probabilistic models to conditional image generation and performs super-resolution through a stochastic denoising process</details> | []() | | |
| Colorization, Inpainting, Uncropping, and JPEG restoration |[Palette: Image-to-Image Diffusion Models](https://arxiv.org/abs/2111.05826) |  2022| <details><summary>read why</summary> A unified framework for image-to-image translation based on conditional diffusion models and evaluates this framework on four challenging image-to-image translation tasks, namely colorization, inpainting, uncropping, and JPEG restoration</details> | []() | | |
| Classifier (+ Classifier-Free) Diffusion Guidance |[Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233)  & [Classifier-Free Diffusion Guidance](https://openreview.net/pdf?id=qw8AKxfYbI)|  2021| <details><summary>read why</summary> DM achieve image sample quality superior to the current SOTA GAN models by improving the U-Net architecture, as well as introducing classifier (+calssifier free) guidance </details> | []() | | |
| Text2Image | [ImageGen](https://arxiv.org/abs/2205.11487)| 2022| <details><summary>read why</summary> text-to-image synthesis</details> | []() | | |
| Efficient DM (Stable Diffusion) |[High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/abs/2112.10752) | 2022| <details><summary>read why</summary> Apply DM in the latent space of powerful pretrained autoencoders to enable training on limited computational resources while retaining their quality and flexibility</details> | []() | | |
| Imagic |[Imagic: Text-Based Real Image Editing with Diffusion Models](https://arxiv.org/abs/2210.09276) | 2022 | <details><summary>read why</summary>Apply complex (e.g., non-rigid) text-guided semantic edits to a single real image</details> | []() | | |
| Text2Video |[Imagen Video: High Definition Video Generation with Diffusion Models](https://arxiv.org/abs/2210.02303) | 2022 | <details><summary>read why</summary>a text-conditional video generation system based on a cascade of video diffusion models</details> | []() | | |
|TTS-Diffusion| [Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech](https://arxiv.org/abs/2105.06337) | 2021 | <details><summary>read why</summary>Text-to-speech model with score-based decoder producing mel-spectrograms by gradually transforming noise predicted by encoder and aligned with text input by means of Monotonic Alignment Search.</details> | []() | | |
| 3D Shape Synthesis |[LION: Latent Point Diffusion Models for 3D Shape Generation](https://arxiv.org/abs/2210.06978) | 2022 | <details><summary>read why</summary>Hierarchical Latent Point Diffusion Model for 3D shape generation. LION is set up as a variational autoencoder (VAE) with a hierarchical latent space that combines a global shape latent representation with a point-structured latent space.</details> | []() | | |
| DreamFusion |[DreamFusion: Text-to-3D using 2D Diffusion](https://arxiv.org/abs/2209.14988) | 2022 | <details><summary>read why</summary>DreamFusion use a pretrained 2D text-to-image diffusion model to perform text-to-3D synthesis</details> | []() | | |
